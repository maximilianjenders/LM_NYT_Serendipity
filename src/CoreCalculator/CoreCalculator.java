package CoreCalculator;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

import CoreCalculator.Parallel.ParallelSerendipitousArticleProbabilityCalculator;
import CoreCalculator.Parallel.ParallelArticleProbabilityCalculator;

import util.DBConnection;
import util.Helper;

import dataclass.Article;
import dataclass.ArticleFeature;
import dataclass.ArticleFeatureMaintainer;
import dataclass.ArticleProbability;

/***
 * Core class for calculation of language model and probabilities that articles were generated by that LM
 * @author Max
 *
 */
public abstract class CoreCalculator {
	protected HashSet<Article> candidateArticles;
	double[] lastEntropies = new double[5];
	boolean entropiesFilled = false;
	protected ArticleFeatureMaintainer fm;
	protected final int THETARED_K = 800;
	
	boolean advancedAlgorithm;
	Article initialArticle = null;
	static int NUMTHREADS = 24;
	ExecutorService executorPool;
	
	protected final int NUMSERENDIPITIOUSRECOMMENDATIONS = 3;
	protected boolean printEntropyData = false;
	protected boolean printArticleComparisonData = false;
	protected boolean printProbabilityData = false;
	protected boolean printInitialDocumentData = false;
	protected boolean printCoreArticleTitles = false;
	protected boolean storeData = false;

	protected String dataSlice = "full";
	
	public void setStoreData(boolean bool) {
		this.storeData = bool;
	}

	public void setPrintEntropyData(boolean printEntropyData) {
		this.printEntropyData = printEntropyData;
	}

	public void setPrintArticleComparisonData(boolean printArticleComparisonData) {
		this.printArticleComparisonData = printArticleComparisonData;
	}

	public void setPrintProbabilityData(boolean printProbabilityData) {
		this.printProbabilityData = printProbabilityData;
	}

	public void setPrintInitialDocumentData(boolean printInitialDocumentData) {
		this.printInitialDocumentData = printInitialDocumentData;
	}
	public void setPrintCoreArticleTitles(boolean printCoreArticleTitles) {
		this.printCoreArticleTitles = printCoreArticleTitles;
	}
	
	public abstract void run(int initialDocumentID, int numRecomendations);

	/***
	 * Calculates the entropy of all documents in a theta and stores it in the 'entropy' instance variable
	 */
	public final void calculateThetaEntropy(HashMap<Integer, Integer> thetaOccurrences) {
		double newEntropy = 0;
		int n = 0;
		for (int featureID : thetaOccurrences.keySet()) {
			n += thetaOccurrences.get(featureID);
		}
		
		for (int featureID : thetaOccurrences.keySet()) {

			//Best estimator: l_i / n || unsmoothed
			double prob = thetaOccurrences.get(featureID) / (n * 1.0);
			//E(x) = - P(x) * log2(P(x))
			newEntropy += prob * (Math.log(prob) / Math.log(2));
		}
		
		
		newEntropy = (-1) * newEntropy;
		setEntropy(newEntropy);
	}
	
	/***
	 * Stores entropy
	 */
	protected final void setEntropy(double entropy) {
		if (! entropiesFilled) {
			for (int i = 0; i < lastEntropies.length; i++) {
				if (lastEntropies[i] == 0) {
					lastEntropies[i] = entropy;
					break;
				}
				if ( i == lastEntropies.length - 1) entropiesFilled = true;
			}
		} else {
			for (int i = 1; i < lastEntropies.length; i++) {
				lastEntropies[i-1] = lastEntropies[i];
			}
			lastEntropies[lastEntropies.length - 1] = entropy;
		}
		
		if (printEntropyData) Helper.print("Entropy is " + entropy + ", with an average delta of " + getAvgEntropyDelta());
	}
	
	/***
	 * Calculates the average delta between entropies
	 * @return
	 */
	protected final double getAvgEntropyDelta() {
		double sum = 0;
		int count = 0;
		//lastEntropies might not be completely filled
		for (int i = 1; i < lastEntropies.length; i++) {
			if (lastEntropies[i] == 0) break; 
			sum += Math.abs(lastEntropies[i - 1] - lastEntropies[i]);
			count++;
		}
		return (count == 0) ? lastEntropies[0] : sum / count;
	}
	
	protected final void removeArticle(Article article, HashSet<Article> documentSet) {
		documentSet.remove(article);
	}
	protected final void removeArticle(int articleID, HashSet<Article> documentSet) {
		for (Article a : documentSet) {
			if (a.getID() == articleID) {
				documentSet.remove(a);
				break;
			}
		}
	}
	/***
	 * Retrieves an article out of a documentSet
	 * @param articleID the id of the article to be found
	 * @param documentSet the set of documents to be searched
	 * @return the Article specified by the articleID, or null if not found
	 */
	protected final Article findArticle(int articleID, HashSet<Article> documentSet) {
		for (Article a : documentSet) {
			if (a.getID() == articleID) {
				return a;
			}
		}
		return null;
	}
	
	public final Article findCandidateArticle(int articleID) {
		for (Article a : candidateArticles) {
			if (a.getID() == articleID) {
				return a;
			}
		}
		return null;
	}
	
	/***
	 * Calculates a language model (i.e., mapping of feature (IDs) to their # of occurrences
	 * @param articles the articles to analyze
	 * @return HashMap of feature occurrences
	 */
	protected final HashMap<Integer, Integer> calculateTheta(HashSet<Article> articles) {
		HashMap<Integer, Integer> occurrences = new HashMap<Integer, Integer>(600000);

		for (Article a : articles) {
			for (ArticleFeature feat : a.getArticleFeatures()) {
				int featureID = feat.getFeatureID();
				if (occurrences.containsKey(featureID)) {
					occurrences.put(featureID, feat.getNumOccurrences() + occurrences.get(featureID));
				} else {
					occurrences.put(featureID, feat.getNumOccurrences());
				}
			}
		}
		return occurrences;
	}

	/***
	 * Adds data for an article to language model
	 * @param article the article to analyze
	 * @param theta the lm
	 */
	protected final void addToTheta(Article article, HashMap<Integer, Integer> theta) {
		for (ArticleFeature feat : article.getArticleFeatures()) {
			int featureID = feat.getFeatureID();
			if (theta.containsKey(featureID)) {
				theta.put(featureID, feat.getNumOccurrences() + theta.get(featureID));
			} else {
				theta.put(featureID, feat.getNumOccurrences());
			}
		}
	}
	
	protected final void extractCandidateArticles() {
		candidateArticles = fm.getArticlesAsSet();
	}

	/***
	 * Finds the k most serendipitous documents 
	 * @param numRecomendations the k
	 * @param articleSet the set from which the candidate articles are drawn
	 * @param numeratorTheta the theta for the numerator
	 * @param denominatorTheta the theta for the denominator
	 */
	public void findSerendipitousDocs(int numRecomendations, HashSet<Article> articleSet, 
			HashMap<Integer, Integer> numeratorTheta, HashMap<Integer, Integer> denominatorTheta) {

		for (int i = 1; i <= numRecomendations; i++) {
			//Parallel jobs to calculate probability
			Set<Future<ArticleProbability>> probabilities = new HashSet<Future<ArticleProbability>>();
			for (Article article : articleSet) {
				Callable<ArticleProbability> callable = new ParallelSerendipitousArticleProbabilityCalculator(article, numeratorTheta, denominatorTheta);
				Future<ArticleProbability> future = executorPool.submit(callable);
				probabilities.add(future);
			}

			//The maximum observed probability yet. 
			double maxLogProbability = Double.NEGATIVE_INFINITY;
			//the articleID of the most probable article
			Article maxArticle = null;

			for (Future<ArticleProbability> future : probabilities) {
				try {
					ArticleProbability prob = future.get();
					if (prob.getLogProbability() > maxLogProbability) {
						maxLogProbability = prob.getLogProbability();
						maxArticle = prob.getArticle();
					}
				} catch (InterruptedException e) {
					Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
					e.printStackTrace();
				} catch (ExecutionException e) {
					Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
					e.printStackTrace();
				}
			}

			removeArticle(maxArticle, articleSet);
			Helper.print("Most serendipitous article for " + initialArticle.getID() + " is " + maxArticle.getID()  + ", " + maxArticle.getTitle() + " (" + maxArticle.getTopic() + ")");
		}


	}
	
	/***
	 * Given a language model, calculates the article that has the highest probability of being created by the language model
	 * @param theta the lm
	 * @return the most probable article
	 */
	protected final Article findMostProbableDocument(HashMap<Integer, Integer> theta) {
		if (candidateArticles.size() == 0) {
			System.err.println("No more candidate articles");
			System.exit(-1);
		}

		Set<Future<ArticleProbability>> probabilities = startParallelProbabilityCalculations(candidateArticles, theta);
				
		
		//The maximum observed probability yet. 
		double maxLogProbability = Double.NEGATIVE_INFINITY;
		//the articleID of the most probable article
		Article a = null;
				
		for (Future<ArticleProbability> future : probabilities) {
			try {
				ArticleProbability prob = future.get();
				if (prob.getLogProbability() > maxLogProbability) {
					maxLogProbability = prob.getLogProbability();
					a = prob.getArticle();
				}
			} catch (InterruptedException e) {
				Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
				e.printStackTrace();
			} catch (ExecutionException e) {
				Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
				e.printStackTrace();
			}
		}
		
		if (printProbabilityData) Helper.print("Most probable document is " + a.getID() + "(" + a.getTopic() + ") " + a.getTitle() + 
				" with logProb = " + maxLogProbability);
		return a;
	}
	
	/***
	 * For faster calculation, parallelization of probability calculations
	 * @param articles articles for which probabilities should be calculated
	 * @param theta the creating lm
	 * @return the Futures of Probabilities
	 */
	protected final Set<Future<ArticleProbability>> startParallelProbabilityCalculations(
			HashSet<Article> articles, HashMap<Integer, Integer> theta) {
		//Parallel jobs to calculate probability
		Set<Future<ArticleProbability>> probabilities = new HashSet<Future<ArticleProbability>>();
		for (Article article : articles) {
			Callable<ArticleProbability> callable = new ParallelArticleProbabilityCalculator(article, theta);
			Future<ArticleProbability> future = executorPool.submit(callable);
			probabilities.add(future);
		}
		return probabilities;
	}
	
	/***
	 * Given a language model, calculates the article that has the lowest probability of being created by the language model
	 * @param theta the lm
	 * @return the least probable article
	 */
	protected final Article findLeastProbableDocument(HashMap<Integer, Integer> theta) {
		if (candidateArticles.size() == 0) {
			System.err.println("No more candidate articles");
			System.exit(-1);
		}
		
		Set<Future<ArticleProbability>> probabilities = startParallelProbabilityCalculations(candidateArticles, theta);

		//The minimum observed probability yet. 
		double minLogProbability = Double.POSITIVE_INFINITY;
		//the articleID of the most probable article
		Article a = null;

		for (Future<ArticleProbability> future : probabilities) {
			try {
				ArticleProbability prob = future.get();
				if (prob.getLogProbability() < minLogProbability) {
					minLogProbability = prob.getLogProbability();
					a = prob.getArticle();
				}
			} catch (InterruptedException e) {
				Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
				e.printStackTrace();
			} catch (ExecutionException e) {
				Helper.printErr("ERROR WHEN CALCULATING PROBABLITIY:");
				e.printStackTrace();
			}

		}
		
		if (printProbabilityData) Helper.print("Least probable document is " + a.getID() + ", " + a.getTitle() + "(" + a.getTopic() + ") with logProb = " + minLogProbability);
		return a;
	}
	
		/***
		 * Calculates thetaRed, a reduced theta containing only the K most frequent terms 
		 * @param k the parameter of how many terms are included
		 * @return the reduced theta
		 */
		protected HashMap<Integer, Integer> calculateThetaRed(int k, HashMap<Integer, Integer> theta) {
			//Map: FeatureID -> Count
			HashMap<Integer, Integer> thetaRedOccurences = new HashMap<Integer, Integer>();
			//dirty, TODO: FIX
			
			for (int i = 0; i < k; i++) {
				int maxFreq = 0;
				int fID = 0;
				for (int key : theta.keySet()) {
					if (theta.get(key) > maxFreq) {
						maxFreq = theta.get(key);
						fID = key;
					}
				}
				thetaRedOccurences.put(fID, maxFreq);
			}
			
			//Print out the ordered frequencies in order to get the best k
//			LinkedList<Integer> s = new LinkedList<Integer>();
//			s.addAll(theta.keySet());
//			Collections.sort(s);
//			for (int i : s) {
//				System.out.println(i);
//			}
			return thetaRedOccurences;
		}
		
	protected abstract void addInitialDocument(int initialDocumentID); 
	protected abstract void findSerendipitousDocs(int numRecommendations);
	protected abstract void extractCoreArticles();
	protected final void execute(int initialDocumentID) {
		addInitialDocument(initialDocumentID);
		extractCoreArticles();
		findSerendipitousDocs(NUMSERENDIPITIOUSRECOMMENDATIONS);
	}
	
	/***
	 * Finds all articles for which there is no intersection between features with the initial article
	 */
	public HashSet<Article> findNonIntersectingCandidates(Article initialArticle) {
		HashMap<Integer, Integer> occurrences = initialArticle.getOccurrences();
		HashSet<Article> nonIntersections = new HashSet<Article>();

		for (Article cand : candidateArticles) {
			boolean overlaps = false;
			for (int feature : occurrences.keySet()) {
				if (cand.getOccurrences().containsKey(feature)) {
					overlaps = true;
					break;
				}
			}
			if (! overlaps) nonIntersections.add(cand);
		}
		return nonIntersections;
	}
	
	
	public abstract void storeData();
	
	public void setDataSlice(String slice) {
		this.dataSlice = slice;
	}

	/***
	 * Loads article data from database 
	 * @param initialArticleID
	 */
	public void restoreFromDB(int initialArticleID) {
		extractCandidateArticles();
		addInitialDocument(initialArticleID);
		
		
		ArrayList<Integer> assignedArticles = DBConnection.getInstance().restoreAssignments(initialArticleID, dataSlice, advancedAlgorithm);
		
		
		assignToMainCore(assignedArticles);
		setRemainingArticlesNonCore();
	}
	
	public abstract void assignToMainCore(ArrayList<Integer> mainArticleIDs);
	public abstract void setRemainingArticlesNonCore();
	
}
